{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6529bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing line 1 of D:\\Programs\\Python\\lib\\site-packages\\vision-1.0.0-py3.9-nspkg.pth:\n",
      "\n",
      "  Traceback (most recent call last):\n",
      "    File \"D:\\Programs\\Python\\lib\\site.py\", line 169, in addpackage\n",
      "      exec(line)\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"<frozen importlib._bootstrap>\", line 562, in module_from_spec\n",
      "  AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\n",
      "Remainder of file ignored\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'D:\\Programs\\Python\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install jovian --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972b627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jovian\n",
    "\n",
    "project_name=\"Coin-temp-file\"\n",
    "jovian.commit(project=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26470dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np \n",
    "import os\n",
    "import json\n",
    "import warnings \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras_preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#from keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e25b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import os\n",
    "from time import time\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, image\n",
    "from keras.utils import np_utils\n",
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe6f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' path of train, test and val data'''\n",
    "\n",
    "path = \"coins/data\"\n",
    "\n",
    "data_train_path =  path + '/train'\n",
    "data_valid_path = path + '/validation'\n",
    "data_test_path =  path + '/test'\n",
    "\n",
    "print(os.listdir(\"coins/data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' reading data '''\n",
    "with open('cat_to_name.json', 'r') as file:\n",
    "    cat_2_name= json.load(file)\n",
    "\n",
    "print(cat_2_name['200'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bdcfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=60\n",
    "\n",
    "# Transforms\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally \n",
    "    height_shift_range=0.1,  # randomly shift images vertically\n",
    "    horizontal_flip=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=True)\n",
    "\n",
    "datagen_valid = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally\n",
    "    height_shift_range=0.1,  # randomly shift images vertically\n",
    "    horizontal_flip=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=True)\n",
    "\n",
    "datagen_test = ImageDataGenerator(\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1844ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen_train.flow_from_directory(\n",
    "        data_train_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "valid_generator = datagen_valid.flow_from_directory(\n",
    "        data_valid_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = datagen_test.flow_from_directory(\n",
    "        data_test_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49859ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Lets have a look at some of our images\n",
    "images, labels = train_generator.next()\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "fig.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "# Lets show the first 32 images of a batch\n",
    "for i, img in enumerate(images[:32]):\n",
    "    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(img)\n",
    "    image_idx = np.argmax(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_dir = {v: k for k, v in train_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "#from keras.applications import MobileNetV2\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "base_model = MobileNetV2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=input_tensor,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling='avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True  # trainable has to be false in order to freeze the layers\n",
    "\n",
    "x = Dense(512, activation='relu')(base_model.output)\n",
    "x = Dropout(.8)(x)\n",
    "\n",
    "predictions = Dense(211, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb208943",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "num_train = len(train_generator.filenames)\n",
    "num_valid = len(valid_generator.filenames)\n",
    "num_test = len(train_generator.filenames)\n",
    "\n",
    "\n",
    "# When to save the model\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "# Reduce learning rate when loss doesn't improve after n epochs\n",
    "scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=5, min_lr=1e-8, verbose=1)\n",
    "\n",
    "# Stop early if model doesn't improve after n epochs\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=12,\n",
    "                              verbose=0, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=num_train//batch_size,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, scheduler, early_stopper],\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=num_valid//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d698807",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mobilenet_trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb23cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(test_generator, steps=num_test//1, verbose=1)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd97699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1e504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e3cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb062a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc32259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a51f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec778d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a2d4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a1224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296909ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3633663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img, real_label):\n",
    "    img = image.img_to_array(img)/255\n",
    "    \n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    img = (img - mean)/std\n",
    "    \n",
    "    img_expand = np.expand_dims(img, axis=0)\n",
    "\n",
    "    prediction = model.predict(img_expand)\n",
    "    prediction_int = np.argmax(prediction)\n",
    "\n",
    "    dir_int = int_to_dir[prediction_int]\n",
    "    label_name = cat_2_name[str(dir_int)]\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    \n",
    "    print(\"Predicted: {}\\nReal:      {}\".format(label_name, cat_2_name[str(real_label)]))\n",
    "    print()\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    random_index = np.random.randint(0, len(test_generator.filenames))\n",
    "    \n",
    "    img = test_generator.filenames[random_index]\n",
    "    img = image.load_img(\"coins/data/test/\"+img, target_size=(224,224))\n",
    "    real_label = test_generator.filenames[random_index].split(\"\\\\\")[0]\n",
    "\n",
    "    get_prediction(img, real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "import pickle\n",
    "\n",
    "with open(\"./SavedModels/model-temp\",\"wb\") as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading saved model\n",
    "with open(\"./SavedModels/model-temp\",\"rb\") as f:\n",
    "    lr=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb37268",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian\n",
    "\n",
    "project_name=\"coin-detector\"\n",
    "jovian.commit(project=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da3445b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
